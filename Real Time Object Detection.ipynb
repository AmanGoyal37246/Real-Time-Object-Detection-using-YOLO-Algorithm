{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard useful data processing imports\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visualisation imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Scikit learn for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Keras Imports - CNN\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Lambda, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_shape = (32,32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model - Sequential Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize = (3, 3)\n",
    "ip_activation = 'relu'\n",
    "ip_conv_0 = Conv2D(filters=32, kernel_size=kernelSize, input_shape=im_shape, activation=ip_activation)\n",
    "cnn.add(ip_conv_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the next Convolutional+Activation layer\n",
    "ip_conv_0_1 = Conv2D(filters=32, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_0_1)\n",
    "\n",
    "\n",
    "# Add the Pooling layer\n",
    "pool_0 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")\n",
    "cnn.add(pool_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding few more layers of convnet and maxpool\n",
    "ip_conv_1 = Conv2D(filters=64, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_1)\n",
    "ip_conv_1_1 = Conv2D(filters=64, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_1_1)\n",
    "\n",
    "\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")\n",
    "cnn.add(pool_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the next Convolutional+Activation layer\n",
    "ip_conv_2_1 = Conv2D(filters=32, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_2_1)\n",
    "ip_conv_2_2 = Conv2D(filters=32, kernel_size=kernelSize, activation=ip_activation)\n",
    "cnn.add(ip_conv_2_2)\n",
    "\n",
    "# Add the Pooling layer\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")\n",
    "cnn.add(pool_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's deactivate around 30% of neurons randomly for training\n",
    "drop_layer_0 = Dropout(0.3)\n",
    "cnn.add(drop_layer_0)\n",
    "cnn.add(Lambda(lambda x: K.squeeze(x, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the flatten layer\n",
    "flat_layer_0 = Flatten()\n",
    "#cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "# Compile the classifier using the configuration we want\n",
    "cnn.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 3, 3, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 1, 32)             0         \n",
      "=================================================================\n",
      "Total params: 92,704\n",
      "Trainable params: 92,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "starting_time = time.time()\n",
    "frame_id = 0\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame_id += 1\n",
    "\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.8, 0.3)\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = confidences[i]\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label + \" \" + str(round(confidence, 2)), (x, y + 30), font, 3, color, 3)\n",
    "\n",
    "\n",
    "\n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps = frame_id / elapsed_time\n",
    "    cv2.putText(frame, \"FPS: \" + str(round(fps, 2)), (10, 50), font, 4, (0, 0, 0), 3)\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
